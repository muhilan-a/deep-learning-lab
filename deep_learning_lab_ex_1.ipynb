{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 1.\tImplement the 2-bit input Tautology (Always ON) Logic Gate using Perceptron Algorithm\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "tA6AueEu22DW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "expected_output = np.array([[1],[1],[1],[1]])\n"
      ],
      "metadata": {
        "id": "hiiX5W2U7S76"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#np.random.seed(0)\n",
        "\n",
        "def sigmoid (x):\n",
        "    return 1/(1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "#Input datasets\n",
        "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "expected_output = np.array([[0],[0],[0],[1]])\n",
        "\n",
        "epochs = 10000\n",
        "lr = 0.1\n",
        "inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n",
        "\n",
        "#Random weights and bias initialization\n",
        "hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n",
        "hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n",
        "print(hidden_bias)\n",
        "output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n",
        "print(output_weights)\n",
        "output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n",
        "\n",
        "print(\"Initial hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Initial hidden biases: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Initial output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Initial output biases: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "\n",
        "#Training algorithm\n",
        "for _ in range(epochs):\n",
        "\t#Forward Propagation\n",
        "\thidden_layer_activation = np.dot(inputs,hidden_weights)\n",
        "\thidden_layer_activation += hidden_bias\n",
        "\thidden_layer_output = sigmoid(hidden_layer_activation)\n",
        "\n",
        "\toutput_layer_activation = np.dot(hidden_layer_output,output_weights)\n",
        "\toutput_layer_activation += output_bias\n",
        "\tpredicted_output = sigmoid(output_layer_activation)\n",
        "\n",
        "\t#Backpropagation\n",
        "\terror = expected_output - predicted_output\n",
        "\td_predicted_output = error * sigmoid_derivative(predicted_output)\n",
        "\n",
        "\terror_hidden_layer = d_predicted_output.dot(output_weights.T)\n",
        "\td_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
        "\n",
        "\t#Updating Weights and Biases\n",
        "\toutput_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n",
        "\toutput_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n",
        "\thidden_weights += inputs.T.dot(d_hidden_layer) * lr\n",
        "\thidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pg1cj8GFuFa",
        "outputId": "a4a25190-7ceb-4ca7-92f3-511894c84ec6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.72564968 0.81757895]]\n",
            "[[0.35938977]\n",
            " [0.92172307]]\n",
            "Initial hidden weights: [0.64178193 0.12851331] [0.30646653 0.1774622 ]\n",
            "Initial hidden biases: [0.72564968 0.81757895]\n",
            "Initial output weights: [0.35938977] [0.92172307]\n",
            "Initial output biases: [0.89408273]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.\tImplement the 2-bit input AND Logic Gate using Perceptron Algorithm"
      ],
      "metadata": {
        "id": "lEBetLVi3mWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "expected_output = np.array([[0],[0],[0],[1]])\n",
        "print(\"Initial hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Initial hidden biases: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Initial output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Initial output biases: \",end='')\n",
        "print(*output_bias)\n",
        "print(\"Final hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Final hidden bias: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Final output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Final output bias: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
        "print(*predicted_output)"
      ],
      "metadata": {
        "id": "UCrDcVF_Fu9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ecf0872-6439-41ee-dcd8-594fcacfbca0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial hidden weights: [-3.2556071   1.84859603] [-3.28423102  1.81323211]\n",
            "Initial hidden biases: [ 4.54285243 -2.13118398]\n",
            "Initial output weights: [-7.22179286] [4.66071525]\n",
            "Initial output biases: [0.13075686]\n",
            "Final hidden weights: [-3.2556071   1.84859603] [-3.28423102  1.81323211]\n",
            "Final hidden bias: [ 4.54285243 -2.13118398]\n",
            "Final output weights: [-7.22179286] [4.66071525]\n",
            "Final output bias: [0.13075686]\n",
            "\n",
            "Output from neural network after 10,000 epochs: [0.00147096] [0.02845863] [0.02859613] [0.95685557]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.\tImplement the 2-bit input OR Logic Gate using Perceptron Algorithm"
      ],
      "metadata": {
        "id": "u4lTh3NE4QHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "expected_output = np.array([[0],[1],[1],[1]])\n",
        "print(\"Initial hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Initial hidden biases: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Initial output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Initial output biases: \",end='')\n",
        "print(*output_bias)\n",
        "print(\"Final hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Final hidden bias: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Final output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Final output bias: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
        "print(*predicted_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up0BQ-J44PMN",
        "outputId": "be155ba4-7437-473b-89f2-0c8b88ff8668"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial hidden weights: [-3.2556071   1.84859603] [-3.28423102  1.81323211]\n",
            "Initial hidden biases: [ 4.54285243 -2.13118398]\n",
            "Initial output weights: [-7.22179286] [4.66071525]\n",
            "Initial output biases: [0.13075686]\n",
            "Final hidden weights: [-3.2556071   1.84859603] [-3.28423102  1.81323211]\n",
            "Final hidden bias: [ 4.54285243 -2.13118398]\n",
            "Final output weights: [-7.22179286] [4.66071525]\n",
            "Final output bias: [0.13075686]\n",
            "\n",
            "Output from neural network after 10,000 epochs: [0.00147096] [0.02845863] [0.02859613] [0.95685557]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.\tImplement the 2-bit input NOR Logic Gate using Perceptron Algorithm"
      ],
      "metadata": {
        "id": "nOD6uRW66TnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "expected_output = np.array([[1],[0],[0],[0]])\n",
        "print(\"Initial hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Initial hidden biases: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Initial output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Initial output biases: \",end='')\n",
        "print(*output_bias)\n",
        "print(\"Final hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Final hidden bias: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Final output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Final output bias: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
        "print(*predicted_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGtI-rXB6Sgt",
        "outputId": "68cebb0c-11e8-4e16-d483-7020d1810ce1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial hidden weights: [-3.2556071   1.84859603] [-3.28423102  1.81323211]\n",
            "Initial hidden biases: [ 4.54285243 -2.13118398]\n",
            "Initial output weights: [-7.22179286] [4.66071525]\n",
            "Initial output biases: [0.13075686]\n",
            "Final hidden weights: [-3.2556071   1.84859603] [-3.28423102  1.81323211]\n",
            "Final hidden bias: [ 4.54285243 -2.13118398]\n",
            "Final output weights: [-7.22179286] [4.66071525]\n",
            "Final output bias: [0.13075686]\n",
            "\n",
            "Output from neural network after 10,000 epochs: [0.00147096] [0.02845863] [0.02859613] [0.95685557]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.\tImplement the 2-bit input NAND Logic Gate using Perceptron Algorithm"
      ],
      "metadata": {
        "id": "jq5iqZ4Q6im0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "expected_output = np.array([[1],[1],[1],[0]])\n",
        "print(\"Initial hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Initial hidden biases: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Initial output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Initial output biases: \",end='')\n",
        "print(*output_bias)\n",
        "print(\"Final hidden weights: \",end='')\n",
        "print(*hidden_weights)\n",
        "print(\"Final hidden bias: \",end='')\n",
        "print(*hidden_bias)\n",
        "print(\"Final output weights: \",end='')\n",
        "print(*output_weights)\n",
        "print(\"Final output bias: \",end='')\n",
        "print(*output_bias)\n",
        "\n",
        "print(\"\\nOutput from neural network after 10,000 epochs: \",end='')\n",
        "print(*predicted_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftuF-bKJ6i5K",
        "outputId": "f7c8a978-cf19-497a-b36d-a34e2004e66b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial hidden weights: [-3.2556071   1.84859603] [-3.28423102  1.81323211]\n",
            "Initial hidden biases: [ 4.54285243 -2.13118398]\n",
            "Initial output weights: [-7.22179286] [4.66071525]\n",
            "Initial output biases: [0.13075686]\n",
            "Final hidden weights: [-3.2556071   1.84859603] [-3.28423102  1.81323211]\n",
            "Final hidden bias: [ 4.54285243 -2.13118398]\n",
            "Final output weights: [-7.22179286] [4.66071525]\n",
            "Final output bias: [0.13075686]\n",
            "\n",
            "Output from neural network after 10,000 epochs: [0.00147096] [0.02845863] [0.02859613] [0.95685557]\n"
          ]
        }
      ]
    }
  ]
}